{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Tensorflow:\n",
    "\n",
    "## Regression Analysis\n",
    "- In statistical modelling RA is a set of statistical processes for predicting the relationships between the dependent and independent variable of a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and Outputs:\n",
    "- Alot of the time defining inputs to the problem is required\n",
    "- User one hot numerical encoding normally, called:\n",
    "  - Predictors\n",
    "  - Features\n",
    "  - Covarients\n",
    "\n",
    "Inputs go through a machine learning algorithm (often alreay exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of a NN:\n",
    "Made up of: input Layer, Hidden Layers and then Output layers\n",
    "\n",
    "### Architecture of a regression mdoel:\n",
    "- Input Layer Shape\n",
    "- Hidden Layers\n",
    "- Neurons per layer\n",
    "- Output layer shape\n",
    "- Hidden activation functions\n",
    "- output activation functions\n",
    "- loss function\n",
    "- optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow:\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data to view and fit:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15db65190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([-7., -4., -1.0, 2.0, 5.0, 8., 11., 14.])\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualise:\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output shapes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for housing price predictino problem\n",
    "\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((),), ())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x[0].shape,\n",
    "output_shape = y[0].shape\n",
    "\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to use 1 X value to predict 1 Y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn numpy arrays into tensors:\n",
    "X = tf.constant(x)\n",
    "y = tf.constant(y)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling:\n",
    "1. Creating a model, define the input and output layers as well as the hidden layers\n",
    "2. Compiliing the model, define the loss function and the optimizer\n",
    "3. Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 964us/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6498 - mae: 9.6498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1682e5c10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed:\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the mode:\n",
    "model.compile(loss=tf.keras.losses.MAE, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model:\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.766022]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using model to make prediction:\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving our model:\n",
    "\n",
    "1. Creation:\n",
    "   - Could increase the number of hidden layers in the NN\n",
    "   - Increase the number of neurons in the layers\n",
    "   - Provide it more input data\n",
    "   - Change the activation function\n",
    "2. Compiling:\n",
    "   - Change the optimisation function of the learning rate of the optimisation function\n",
    "3. Fitting a model:\n",
    "   - Fit the model over more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 14.0395 - mae: 14.0395\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.9332 - mae: 58.9332\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7141 - mae: 11.7141\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.6049 - mae: 12.6049\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9580 - mae: 8.9580\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9200 - mae: 8.9200\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3383 - mae: 5.3383\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9626 - mae: 3.9626\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9932 - mae: 3.9932\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6317 - mae: 7.6317\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7202 - mae: 2.7202\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0914 - mae: 5.0914\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9339 - mae: 3.9339\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4949 - mae: 8.4949\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9147 - mae: 0.9147\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4321 - mae: 2.4321\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3564 - mae: 2.3564\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7741 - mae: 1.7741\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1688 - mae: 2.1688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3393 - mae: 2.3393\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7959 - mae: 1.7959\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1382 - mae: 2.1382\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2467 - mae: 1.2467\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6222 - mae: 1.6222\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8038 - mae: 1.8038\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5013 - mae: 1.5013\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3139 - mae: 2.3139\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7268 - mae: 1.7268\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0033 - mae: 2.0033\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0737 - mae: 2.0737\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9834 - mae: 0.9834\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2243 - mae: 3.2243\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1926 - mae: 1.1926\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8486 - mae: 2.8486\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9601 - mae: 3.9601\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3459 - mae: 3.3459\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0314 - mae: 1.0314\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2084 - mae: 3.2084\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4023 - mae: 3.4023\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9286 - mae: 0.9286\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1656 - mae: 3.1656\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3388 - mae: 4.3388\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3152 - mae: 4.3152\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4121 - mae: 3.4121\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7787 - mae: 1.7787\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4802 - mae: 2.4802\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5832 - mae: 3.5832\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0676 - mae: 2.0676\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7313 - mae: 1.7313\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7898 - mae: 2.7898\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5616 - mae: 2.5616\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2380 - mae: 1.2380\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8505 - mae: 1.8505\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0039 - mae: 2.0039\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8353 - mae: 0.8353\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1411 - mae: 2.1411\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4507 - mae: 2.4507\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7482 - mae: 1.7482\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4134 - mae: 1.4134\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5965 - mae: 2.5965\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4939 - mae: 1.4939\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6145 - mae: 1.6145\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9285 - mae: 1.9285\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2929 - mae: 1.2929\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6413 - mae: 1.6413\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3044 - mae: 1.3044\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9334 - mae: 1.9334\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1322 - mae: 1.1322\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3387 - mae: 1.3387\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1729 - mae: 1.1729\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1165 - mae: 1.1165\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6581 - mae: 0.6581\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7007 - mae: 1.7007\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6031 - mae: 0.6031\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6946 - mae: 2.6946\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8787 - mae: 1.8787\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8497 - mae: 1.8497\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4329 - mae: 2.4329\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3943 - mae: 1.3943\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0666 - mae: 2.0666\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5296 - mae: 2.5296\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9305 - mae: 0.9305\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5565 - mae: 2.5565\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4862 - mae: 3.4862\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4035 - mae: 3.4035\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4093 - mae: 2.4093\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6557 - mae: 0.6557\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1841 - mae: 2.1841\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6624 - mae: 1.6624\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1608 - mae: 1.1608\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6314 - mae: 1.6314\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6724 - mae: 0.6724\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2405 - mae: 2.2405\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2479 - mae: 2.2479\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6080 - mae: 0.6080\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5013 - mae: 0.5013\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9079 - mae: 1.9079\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4974 - mae: 1.4974\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2205 - mae: 1.2205\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5056 - mae: 1.5056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16943fc10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Larger model:\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Hidden Layers:\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), metrics=[\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.626812]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Model:\n",
    "\n",
    "In practice a typical workflow is:\n",
    "```\n",
    "build a model -> fit it -> evaluate -> tweka it -> fit -> eval -> rinse and repeat\n",
    "```\n",
    "\n",
    "Beacuse each parameter can be altered they are refered to as ***hyper peramters***\n",
    "\n",
    "***Visualisation*** is key to evaluation\n",
    "\n",
    "Visualise the:\n",
    "- Data\n",
    "- Model itself\n",
    "- Model training\n",
    "- predictions of the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bigger datasetL\n",
    "\n",
    "X = tf.range(-100, 100, 4)\n",
    "\n",
    "# Make labels for the dataset:\n",
    "\n",
    "y = X + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x16970d5e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the input data:\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The three sets of data:\n",
    "\n",
    "* Traning set - the set the model learns from (70-80% of data)\n",
    "* Validation set - model gets tuned on this data (10-15% of data)\n",
    "* Test set - model gets evaluated on this data to test learning (10-15%) of the data\n",
    "\n",
    "Aiming for the neaural network to achieve generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of samples:\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we only have small sample we will skip the validation set:\n",
    "\n",
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[:40] # first 40 samples\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:]  # Last 19 samples\n",
    "y_test = y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 63.2266 - mae: 63.2266\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.1970 - mae: 18.1970\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1662 - mae: 16.1662\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 854us/step - loss: 10.1129 - mae: 10.1129\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 866us/step - loss: 15.5271 - mae: 15.5271\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 877us/step - loss: 11.8406 - mae: 11.8406\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 691us/step - loss: 9.1482 - mae: 9.1482\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 935us/step - loss: 13.6424 - mae: 13.6424\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 704us/step - loss: 13.9040 - mae: 13.9040\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0136 - mae: 10.0136\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 859us/step - loss: 9.9856 - mae: 9.9856\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 952us/step - loss: 9.9267 - mae: 9.9267\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7649 - mae: 9.7649\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5656 - mae: 10.5656\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7844 - mae: 13.7844\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 903us/step - loss: 12.3916 - mae: 12.3916\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1895 - mae: 10.1895\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6696 - mae: 10.6696\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0831 - mae: 10.0831\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8775 - mae: 10.8775\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 792us/step - loss: 12.1006 - mae: 12.1006\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5903 - mae: 9.5903\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9995 - mae: 8.9995\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8105 - mae: 9.8105\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7070 - mae: 9.7070\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 897us/step - loss: 9.8359 - mae: 9.8359\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9016 - mae: 9.9016\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 988us/step - loss: 9.6553 - mae: 9.6553\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5417 - mae: 9.5417\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 914us/step - loss: 9.7986 - mae: 9.7986\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 846us/step - loss: 8.8714 - mae: 8.8714\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8203 - mae: 9.8203\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 876us/step - loss: 9.4605 - mae: 9.4605\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7860 - mae: 9.7860\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 839us/step - loss: 11.9235 - mae: 11.9235\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6355 - mae: 11.6355\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8955 - mae: 10.8955\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5492 - mae: 9.5492\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6671 - mae: 12.6671\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 921us/step - loss: 11.7218 - mae: 11.7218\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4887 - mae: 11.4887\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3621 - mae: 9.3621\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 792us/step - loss: 9.6971 - mae: 9.6971\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 969us/step - loss: 9.5317 - mae: 9.5317\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 942us/step - loss: 9.6652 - mae: 9.6652\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 743us/step - loss: 9.1775 - mae: 9.1775\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 887us/step - loss: 9.2786 - mae: 9.2786\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 832us/step - loss: 9.6900 - mae: 9.6900\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 915us/step - loss: 13.8231 - mae: 13.8231\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 922us/step - loss: 8.7587 - mae: 8.7587\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9927 - mae: 10.9927\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 981us/step - loss: 9.0812 - mae: 9.0812\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 939us/step - loss: 9.8837 - mae: 9.8837\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.6648 - mae: 16.6648\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8236 - mae: 9.8236\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 703us/step - loss: 12.3396 - mae: 12.3396\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 827us/step - loss: 9.1796 - mae: 9.1796\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 978us/step - loss: 9.2536 - mae: 9.2536\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0739 - mae: 9.0739\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5225 - mae: 10.5225\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 964us/step - loss: 9.1356 - mae: 9.1356\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9638 - mae: 9.9638\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 12.0015 - mae: 12.0015\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 793us/step - loss: 9.5175 - mae: 9.5175\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0046 - mae: 9.0046\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 874us/step - loss: 8.9988 - mae: 8.9988\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1140 - mae: 9.1140\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 956us/step - loss: 9.2258 - mae: 9.2258\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 928us/step - loss: 9.2211 - mae: 9.2211\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 958us/step - loss: 9.4810 - mae: 9.4810\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9262 - mae: 8.9262\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0049 - mae: 10.0049\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9554 - mae: 11.9554\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6053 - mae: 8.6053\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.7896 - mae: 8.7896\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8352 - mae: 8.8352\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2212 - mae: 8.2212\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2140 - mae: 11.2140\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2009 - mae: 13.2009\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3431 - mae: 14.3431\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.2888 - mae: 16.2888\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5796 - mae: 9.5796\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6682 - mae: 8.6682\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7672 - mae: 8.7672\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 952us/step - loss: 9.0354 - mae: 9.0354\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1914 - mae: 9.1914\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7396 - mae: 8.7396\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 789us/step - loss: 8.8827 - mae: 8.8827\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6921 - mae: 8.6921\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 916us/step - loss: 8.7421 - mae: 8.7421\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 929us/step - loss: 8.6088 - mae: 8.6088\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2006 - mae: 9.2006\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9274 - mae: 9.9274\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8511 - mae: 12.8511\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1768 - mae: 9.1768\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5582 - mae: 10.5582\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 693us/step - loss: 14.7756 - mae: 14.7756\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8706 - mae: 10.8706\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 879us/step - loss: 14.9341 - mae: 14.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1697d79a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model which builds automatically by defining th input shape arg:\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1])\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(), metrics=[\"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.summary() gives the layers, output shape and the parameters, Dense is a fully connected layer\n",
    "\n",
    "* Total params: Total number of parameters in the model\n",
    "* Trainable parameters: parameters the model can update as it trains\n",
    "* Non-trainable parameters: Paramters that are not updated when trained, occurs when brining in pretrained models to learn using transfer learning\n",
    "\n",
    "### Weights and Biases\n",
    "* Each dense layer contains weights and biases for each layer, these are changed during the learning in order to come to better learning conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 42.5345 - mae: 42.5345\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 868us/step - loss: 39.1160 - mae: 39.1160\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 892us/step - loss: 35.5600 - mae: 35.5600\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 857us/step - loss: 32.2152 - mae: 32.2152\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 694us/step - loss: 29.0249 - mae: 29.0249\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 815us/step - loss: 26.1898 - mae: 26.1898\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 912us/step - loss: 23.5915 - mae: 23.5915\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 634us/step - loss: 20.9329 - mae: 20.9329\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2865 - mae: 18.2865\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.2482 - mae: 16.2482\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.4797 - mae: 14.4797\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 725us/step - loss: 12.6965 - mae: 12.6965\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 722us/step - loss: 11.1948 - mae: 11.1948\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 956us/step - loss: 9.9701 - mae: 9.9701\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 896us/step - loss: 9.0727 - mae: 9.0727\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5387 - mae: 8.5387\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2167 - mae: 8.2167\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9082 - mae: 7.9082\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 820us/step - loss: 7.8017 - mae: 7.8017\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6392 - mae: 7.6392\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 972us/step - loss: 7.6167 - mae: 7.6167\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 869us/step - loss: 7.6665 - mae: 7.6665\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6365 - mae: 7.6365\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7477 - mae: 7.7477\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7342 - mae: 7.7342\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 868us/step - loss: 7.6447 - mae: 7.6447\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6164 - mae: 7.6164\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6190 - mae: 7.6190\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6789 - mae: 7.6789\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 827us/step - loss: 7.6073 - mae: 7.6073\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 941us/step - loss: 7.7203 - mae: 7.7203\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7552 - mae: 7.7552\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 782us/step - loss: 7.6433 - mae: 7.6433\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6076 - mae: 7.6076\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 982us/step - loss: 7.7209 - mae: 7.7209\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9958 - mae: 7.9958\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6677 - mae: 7.6677\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6319 - mae: 7.6319\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5987 - mae: 7.5987\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6008 - mae: 7.6008\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6613 - mae: 7.6613\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 900us/step - loss: 7.5870 - mae: 7.5870\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5932 - mae: 7.5932\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6238 - mae: 7.6238\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7125 - mae: 7.7125\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8035 - mae: 7.8035\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6771 - mae: 7.6771\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 881us/step - loss: 7.7398 - mae: 7.7398\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 874us/step - loss: 7.6553 - mae: 7.6553\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8126 - mae: 7.8126\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 912us/step - loss: 7.6137 - mae: 7.6137\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6961 - mae: 7.6961\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 891us/step - loss: 7.7108 - mae: 7.7108\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7654 - mae: 7.7654\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 968us/step - loss: 7.5848 - mae: 7.5848\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6266 - mae: 7.6266\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8786 - mae: 7.8786\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 849us/step - loss: 7.6702 - mae: 7.6702\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5831 - mae: 7.5831\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5864 - mae: 7.5864\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 840us/step - loss: 7.5839 - mae: 7.5839\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6504 - mae: 7.6504\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 641us/step - loss: 7.6564 - mae: 7.6564\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8055 - mae: 7.8055\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 7.5815 - mae: 7.5815\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5663 - mae: 7.5663\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 986us/step - loss: 7.6074 - mae: 7.6074\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 869us/step - loss: 7.5633 - mae: 7.5633\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6111 - mae: 7.6111\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 830us/step - loss: 7.6084 - mae: 7.6084\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9296 - mae: 7.9296\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6909 - mae: 7.6909\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 982us/step - loss: 7.6349 - mae: 7.6349\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 787us/step - loss: 7.7197 - mae: 7.7197\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 823us/step - loss: 7.6169 - mae: 7.6169\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 978us/step - loss: 7.6127 - mae: 7.6127\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5649 - mae: 7.5649\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5988 - mae: 7.5988\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5797 - mae: 7.5797\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6160 - mae: 7.6160\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6053 - mae: 7.6053\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5498 - mae: 7.5498\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5904 - mae: 7.5904\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5687 - mae: 7.5687\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5889 - mae: 7.5889\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6362 - mae: 7.6362\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8440 - mae: 7.8440\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 926us/step - loss: 7.9867 - mae: 7.9867\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5684 - mae: 7.5684\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5749 - mae: 7.5749\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 741us/step - loss: 7.5861 - mae: 7.5861\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6026 - mae: 7.6026\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 797us/step - loss: 7.5932 - mae: 7.5932\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5431 - mae: 7.5431\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7128 - mae: 7.7128\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5936 - mae: 7.5936\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 899us/step - loss: 7.6586 - mae: 7.6586\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5598 - mae: 7.5598\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5359 - mae: 7.5359\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5413 - mae: 7.5413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a153850>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model 1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name=\"Model 1\")\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"))\n",
    "model.add(tf.keras.layers.Dense(1, name=\"output_layer\"))\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e4597d0768e28d95a0c075d0fa9a599a1e280d3a22fb0bb73315c9a22ec994a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
